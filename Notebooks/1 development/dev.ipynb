{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from scipy.stats import zscore\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = \"../../data/raw/\"\n",
    "train = pd.read_csv(os.path.join(data_path + \"train_values.csv\"))\n",
    "labels = pd.read_csv(os.path.join(data_path + \"train_labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect hist of the data\n",
    "\n",
    "def get_hist(df, hist_x_row=4):\n",
    "    \"\"\"diagnostic tool to inspect the distribution of the data.\n",
    "    It returns a histogram of each column in the dataframe.\n",
    "    \"\"\"\n",
    "    n_cols = np.ceil(len(df.columns)/hist_x_row).astype(int)\n",
    "    plt.figure(figsize=(20, 40))\n",
    "    for i, col in enumerate(df.columns):\n",
    "        plt.subplot(n_cols, hist_x_row, i+1)\n",
    "        df[col].hist()\n",
    "        plt.title(col + ' - ' + str(df[col].dtype)) \n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "\n",
    "\n",
    "get_hist(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary vars into objects\n",
    "\n",
    "for col in train.columns:\n",
    "    if len(train[col].unique()) == 2:\n",
    "        print(col, train[col].unique())\n",
    "        train[col] = train[col].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check outliers\n",
    "\n",
    "def remove_outliers(df, z_level=3.):\n",
    "    \"\"\"Remove outliers from the dataset using zscore.\n",
    "    \"\"\"\n",
    "    num_cols = df.select_dtypes(include='number')\n",
    "    df_z = num_cols.apply(zscore)\n",
    "    outliers = abs(df_z) > z_level\n",
    "    row_to_remove = np.where(outliers.any(axis=1))[0]\n",
    "    print(f'tot number of outliers: {len(row_to_remove)}')\n",
    "    for col in df_z.columns:\n",
    "        print(f'- {col} - number of outliers: {len(df_z[abs(df_z[col]) > z_level])}')\n",
    "    \n",
    "    return df.drop(row_to_remove), row_to_remove\n",
    "\n",
    "train, row_to_remove = remove_outliers(train)\n",
    "\n",
    "# visualize distributions\n",
    "get_hist(train.select_dtypes(include='number'), figsize=(20,20))\n",
    "# get_hist(train_raw.select_dtypes(include='number'), figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping vars for scaling\n",
    "\n",
    "standard_scaler_cols = ['age', 'area_percentage']\n",
    "robust_scaler_cols = []\n",
    "baseN_enc_cols = []\n",
    "ordinal_enc_cols = ['ground_floor_type', 'position']\n",
    "one_hot_cols = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "\n",
    "labels = labels.drop(['building_id'], axis=1)\n",
    "labels = labels.drop(row_to_remove)\n",
    "train = train.drop(['building_id'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buiding pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('standard_scaler', StandardScaler(), standard_scaler_cols),\n",
    "        ('robust_scaler', RobustScaler(), robust_scaler_cols),\n",
    "        ('baseN_encoder', ce.BaseNEncoder(cols=baseN_enc_cols), baseN_enc_cols),\n",
    "        # ('ordinal_encoder', OrdinalEncoder(categories=[...], handle_unknown='use_encoded_value', unknown_value=-1), ordinal_enc_cols),\n",
    "        ('one_hot_encoder', OneHotEncoder(), one_hot_cols),\n",
    "    ])\n",
    "\n",
    "pipeline_lr = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# pipeline_rf = Pipeline(steps=[\n",
    "#     ('preprocessing', preprocessor),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and evaluate\n",
    "models = [pipeline_lr]#, pipeline_rf]#, pipeline_xg]\n",
    "models_name = ['pipeline_lr', 'pipeline_rf', 'pipeline_xg']\n",
    "\n",
    "for mod_name, mod in zip(models_name, models):\n",
    "    y_pred = mod.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='micro')\n",
    "    print(f'{mod_name:1}: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
